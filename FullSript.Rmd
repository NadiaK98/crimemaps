---
title: "Crime mapping in R"
author: "Nads"
date: "25/10/2021"
output: html_document
toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Prerequisite 

This workshop is suitable for those beginer to intermediate in R. It requires you know how to set your working directory, how to read data into R.

- Section on how to download the crime data 
- Section on how to download shapefile 
- Download population stats - maybe for rates? 


Using open source police recorded crime statistics this workshop will demonstrate how to map crime data in R using sf and ggplot



# Topic 1 - Intro to spatial data / point data


```{r load packages }
# for data reading/manipulation 
library(dplyr)
library(tidyr)
library(readr)
library(tibble)
library(janitor)
# for spatial data and gis
library(sf)
library(ggplot2)
library(ggspatial)
library(spdep)
library(leaflet) 
library(RColorBrewer)
library(tmap)
```



## Downloading the crime data 

 *https://data.police.uk/*. 

Select January 2019 to December 2019, from the City of London Police and click 'Include Crime Data'. Download and unzip the data into your working directory

Read in just the January 2019 month of data


```{r crime data}
#unzip(file.choose())
crime01_19 <- read_csv("Data/2020-08/2020-08-surrey-street.csv") %>% 
  janitor::clean_names() 

#explore variables
glimpse(crime01_19)

```

Points, lines and polygon 

- Our coordinate variables (the latitude and longitude) are known as point data 
- The 'location' variable represents the line. This is normally define by a street or junction 
- The 'lsoa name' represent our polygon (bourough, wards, districts etc). LSOA refers to the Lower Layer Super Output Areas which are a unit measure in census geogrpahy 





## Simple Features

Simple Features is a common R language, known as sf packages, that allow you to handle and manipualte the UoA (points, lines and polyons). It allows you store spatial objects and such

Features refers to the property that linestring and polygons are built from points by straight line segments

- sf vs sp 


First step is to transform you ordinary data into an sf object using st_as_sf compromising of three components
- data, coords, and crs 

```{r simple features }
#Including NAs
sf <- st_as_sf(crime01_19,                                
                      coords = c("longitude", "latitude"),
                      crs = 4326,
                      na.fail = FALSE)   
class(sf)


# Removing NAs
sum(is.na(crime01_19$latitude))

crime01_19_na <- crime01_19 %>%
   drop_na(latitude)

sf2 <- st_as_sf(crime01_19_na,                                
                      coords = c("longitude", "latitude"),
                      crs = 4326)   

```



## Mapping point data


```{r}
#### Briefly explore the trend
ggplot(sf, aes(x = crime_type)) + 
  geom_bar()


#### Plot the point data
ggplot() + 
  annotation_map_tile() +
  geom_sf(data = sf)


#### Subsetting for just ASB 
asb <- subset(sf, crime_type == "Anti-social behaviour")
ggplot() +
  annotation_map_tile() +
  geom_sf(data = sf2) 



```




\newpage 


# Topic 2 - Shapefiles 

What are Shapefiles? 

They represent a geospatial vector that is used for GIS software. Shapefiles store both geogrpahic location and its associated attribute infomraiton 

The shapefile format stores the data as primitive geometric shapes like points, lines, and polygons. These shapes, together with data attributes that are linked to each shape, create the representation of the geographic data.

They contain four mandatory file extensions (.shx, .shp, .dbf and the .prj). 
- The .shp contains the geometry data (a 2D axis ordering of coordinate data)
- The .shx contains the positional index of the feature geometry 
- The .dbf contins the attributes for each shape
- The .prj contains the cs and projection information


- Mention crime data and criminology using LSOA as the main census geogrpahy 


To optain boundary data we will use the  https://borders.ukdataservice.ac.uk/bds.html 


Steps to download: 

Select; England, Statistical Building Block, 2011 and later
Click 'Find' 
Select 'English Lower Layer Super Output Areas' 
Click 'List Areas' 
Select 'Surrey Health' 
Click 'Extract Boundary Data' 


Read in the Shapefile for 'Surrey Heath' 

```{r read and plot the boundary for surrey heath}
 
shp_file <- st_read("Data/Shapefile/england_lsoa_2011.shp")

ggplot() + 
  geom_sf(data = shp_file)

```


Count the crimes per lsoa 

```{r crimes per lsoa}
crimes_per_lsoa <- crime01_19 %>%
  group_by(lsoa_code) %>%
  summarise(count=n())
```


Join the crimes per lsoa to the shapefile 

```{r merge the data}

surrey_lsoa <- left_join(shp_file, crimes_per_lsoa, by = c("code" = "lsoa_code"))

#map the data
ggplot() + 
  annotation_map_tile() + 
  geom_sf(data = surrey_lsoa, aes(fill = count), alpha = 0.5) + 
  scale_fill_gradient2(name ="Number of crimes")

```





## Plotting via the 'tmap' package


```{r}
tm_shape(surrey_lsoa) + 
  tm_fill("count") + 
  tm_borders(alpha = 0.3)
```


How can we better visualise counts? Count data does not equally represent the population distribution at hand, tmaps allows you to add different 'styles' 

The different styles result in different clustering mechanism, tmaps have available on 'jenks'or 'Standard Deviation' 


In this example I've used 'kmeans'. k-means clustering is a method of vector quantisation, originally from signal processing, that aims to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean, serving as a prototype of the cluster.

```{r}
tm_shape(surrey_lsoa) + 
  tm_fill("count", style = "kmeans") + 
  tm_borders(alpha = 0.3)
```




## Topic 3: Plotting Distribution / Dasymetric Mapping 

Count data is not entirely accurate of population density 


For this you can use census data 

```{r}
pop <- read_csv("Data/Census Population/Data_UNIT_URESPOP.csv") %>% slice(3:47) %>% 
  select(2,3,6,7) %>%
  janitor::clean_names() %>%
  rename(pop_density = f2383, 
         pop_count = f136983) %>% 
  mutate(pop_count = as.numeric(pop_count))



```



Again we join this to our surrey_lsoa file, by matching the LSOAs


```{r}
surrey_lsoa <- left_join(surrey_lsoa, pop, by = c("code"="geo_code"))

```

Now you will see the census data has merged into the shapefile. 
A crime rate is calculated by dividing the number of reported by the toal population, and then multiplied by 100,000. 

In this case that would be the count variable, divided by the 'pop' variable, and then times by 1000 (we use 1000 as this is the average population of an LSOA, if you were using larger UoA you can choose to multiply by 100,000. Just remember what affect this will have on your rate and how this then interpreted across your results)

In order to work out the crime rate, we need to create a new variable that takes the count/pop*10000

```{r}
surrey_lsoa <- surrey_lsoa %>% 
  mutate(crime_rate = (count/pop_count)*1000)

```



Now lets explore these trends using ggplot and tmap 

##ggplot

```{r}
ggplot() + 
  annotation_map_tile() + 
  geom_sf(data = surrey_lsoa, aes(fill = crime_rate), alpha = 0.5) + 
  scale_fill_gradient2(name ="Number of crimes")
```


##tmaps 


```{r}
tm_shape(surrey_lsoa) + 
  tm_fill("crime_rate", style = "quantile") + 
  tm_borders(alpha = 0.3)
```







###

i.e. solution for mapping population densitiy relative to reisdential land-use

Areal requires your data to be sf objects and and to be re-projected  - are data checks both these boxes


```{r}
install.packages("areal")
library(areal)

aw_interpolate(ar_stl_wards, tid = WARD, source = ar_stl_race, sid = "GEOID", 
               weight = "sum", output = "sf", extensive = "TOTAL_E")

```









# Extra Topic: Interactive Maps; Leaflet

```{r}

## Subsetting for just ASB 
asb <- subset(crime01_19, crime_type == "Anti-social behaviour")

m <- leaflet(data = asb) %>%
  addProviderTiles("Stamen.Toner") %>% 
  addMarkers(lng=~longitude, lat=~latitude, popup=~as.character(location), label = ~as.character(location))
m

```














